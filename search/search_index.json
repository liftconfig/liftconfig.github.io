{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"liftConfig","text":"<p>A Network Engineer's journey into automation, cloud, and coding.</p>"},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#iac","title":"IaC","text":"<ul> <li>Terraform</li> </ul>"},{"location":"tags/#terraform","title":"Terraform","text":"<ul> <li>Terraform</li> </ul>"},{"location":"tags/#coding","title":"coding","text":"<ul> <li>Hello World</li> </ul>"},{"location":"tags/#networking","title":"networking","text":"<ul> <li>Hello World</li> </ul>"},{"location":"about/about-me/","title":"About Me","text":"<p>Father, husband, network engineer, powerlifter. Located in Western Australia.</p> <p>To contact me, reach out on Linkedin or email.</p>"},{"location":"about/gym-setup/","title":"Gym Setup","text":"<p>This is a video walk-through of my home gym from 2018. There's been a few minor changes, but the majority of equipment is still the same. Although life has become a lot busier since becoming a father, I still believe it's important to take the time to maintain strength &amp; fitness especially as we age.</p> <p></p>"},{"location":"about/office-setup/","title":"Office Setup","text":"<p>Since working from home I've been refining my office setup with an emphasis on ergonomics. I'm a believer in investing in high quality tools to increase efficiency and make long sessions working and studying more enjoyable. Below is a breakdown of the equipment I'm currently using.</p> <p> </p>"},{"location":"about/office-setup/#equipment","title":"Equipment","text":""},{"location":"about/office-setup/#laptop-macbook-pro","title":"Laptop: MacBook Pro","text":"<p>The new ARM processors are serious workhorses and due to the high quality 16\" retina display I use it as a secondary monitor.</p>"},{"location":"about/office-setup/#monitor-apple-studio-display","title":"Monitor: Apple Studio Display","text":"<p>I spent a long time researching monitors before settling on the ASD. I was considering an ultrawide (Samsung G95NC or similar for the extra screen real estate) but ultimately ended up with the ASD for the following reasons:</p> <ol> <li>The screen is only being used for productivity. I spend the majority of my time in a terminal or IDE so picture quality and text sharpness is of primary importance.</li> <li>There are limited 5K/6K monitor options on the market. These high resolutions both look great but also allow macOS to scale efficiently.</li> <li>When using the monitor with the MBP it wakes from sleep almost instantly, and you can control the monitor functions (brightness, volume) using the native macOS controls.</li> <li>Integrated speakers, webcam, and 4 port dock. The speakers are great considering they are built into the monitor. The webcam not so much, but it's still fine for online meetings.</li> <li>Apple support is second to none. I've heard nightmare stories trying to get support from Samsung, LG etc.</li> </ol> <p>Before the ASD my monitor setup consisted of 2x 28\" 4K Samsung monitors + MBP display. The reduction in screen real estate is a downside, but I have found less neck strain since removing the 28\" side monitor. The upside is the ASD display quality is far superior. I have also added an iPad with sidecar for some additional screen real estate since using the ASD. I would consider upgrading to a 32\" 6K display if a reasonable priced option becomes available.</p> <p>On the rear of the ASD I've added a LED light strip for back lighting. This provides excellent relief from eye strain during long sessions. I would recommend an adjustable LED strip as it allows the lights to be dimmed while working in the evening.</p>"},{"location":"about/office-setup/#tablet-ipad-109","title":"Tablet: iPad 10.9\"","text":"<p>As mentioned above, this is used with sidecar for extra screen real estate. Usually I'll keep Teams or Outlook open on the iPad. Being able to disconnect it at the end of the day and use it as a regular tablet is also a big benefit. I've found it's an invaluable tool for studying on the go (PDFs, Notion, Udemy etc). I'll likely be looking to upgrade to a 12.9\" when the 2024 models are available.</p> <p>As a side note: I'm not a fan of Safari, but I've found synced tab groups to be very useful to maintain tab consistency across the laptop, tablet, and phone. The tab sync implementation I've seen on other browsers doesn't seem to be as good at maintaining open tabs or as quick to update tab state.</p>"},{"location":"about/office-setup/#headphones-airpods-pro","title":"Headphones: AirPods Pro","text":"<p>I've been using these since they were released in 2019. Active noise cancellation is a must when working from home or a busy office. The battery life, sound quality, and portability mean they are my go-to headphones for both work and study.</p>"},{"location":"about/office-setup/#keyboard-dygma-raise","title":"Keyboard: Dygma Raise","text":"<p>I first stumbled across the Raise when researching ergonomic keyboards. Split keyboards allow the wrists and shoulders to be in a more natural and neutral position. I use the raise for the following reasons:</p> <ol> <li>It uses a standard keyboard layout. I didn't want the pain of switching between something more custom like the ZSA Moonlander and a regular keyboard.</li> <li>It has great software for customising keys, layers, and macros.</li> <li>An OEM tenting kit is available which helps with ergonomics</li> <li>Hot swappable mechanical switches. I originally ordered the Raise with Kailh Silent Browns. They weren't bad, but I've found my preference is for a silent tactile switch. I'm currently using Outemu Cream yellows which is my favourite switch so far.</li> </ol> <p>For anyone starting with a split/ergo keyboard, I highly recommend monkeytype for getting your touch typing back up to speed. There's some great funbox modes which can hit any weak points in your typing game. I personally like the wiki mode which gives a more real-world typing test.</p>"},{"location":"about/office-setup/#trackball-ploopy-classic","title":"Trackball: Ploopy Classic","text":"<p>Due to my HOTAS inspired keyboard &amp; chair setup I had to use a trackpad or trackball. I did initially test the Magic Trackpad, but I found it inefficient and slow for mouse heavy tasks. When researching trackballs, I found the Ploopy had some excellent reviews praising both it's build quality (high quality switches) and ergonomics. The design is essentially an upgraded replica of the Microsoft Trackball Explorer. This is my first trackball and I'm now a convert, using it both at home and in the office. MacOS SteerMouse is a must when using a trackball as it allows you to customise everything about the device, as well as add per app behaviour and macros. Autoscroll is also a game changer as it enables 2D scrolling using the trackball when a button is held down. SteerMouse will allow you to adjust the autoscroll scrolling speed independent of the standard mouse cursor speed.</p>"},{"location":"about/office-setup/#chair-hermon-miller-aeron","title":"Chair: Hermon Miller Aeron","text":"<p>Remastered edition size C with the aftermarket Atlas headrest and rollerblade wheels. Aerons are a gold standard in the ergonomic chair world due to their level of customisation. I found the post in this Reddit thread by a HM product manager to be the most useful explanation of how to properly set up the chair. I typically use it with the tilt adjuster unlocked (for that floating feeling) in a 90 degree upright task based position. The only time I use the headrest to support my head is on the odd occasion I'm leaning back in the chair, the rest of the time I use it as a guide to feel where my head and neck should be to try and limit forward head posture.</p> <p>I use the following components for the HOTAS inspired keyboard mount setup:</p> <ul> <li>2x Bracket Pole Mount Double Arm</li> <li>2x Steel VESA TV mount bracket</li> </ul> <p>This Reddit thread provides the details on how to assemble.</p> <p>Prior to this setup I did try using an adjustable keyboard tray, but I found it didn't provide the level of customisation required. Ergonomics need to be tailored for the individuals body type and limb proportions. Having longer arms and a relatively short torso I found my legs would be touching the underside of a traditional tray or desk, but my forearms and wrists would still have to angle upwards putting pressure on the ulnar nerve in the forearm. With a split keyboard on the above mounts I can use the keyboard in a tented position slightly lower than the Aeron's arm rests. This allows the chest to open up, the shoulders &amp; upper back to sit against the chair back, and the arms to remain in a supinator position with forearms aligned with the wrists. In this position, the arms and wrists are floating above the keyboard with the keys directly below the fingertips. I've made many minor adjustments to the angles and heights of the monitor arms and brackets over time, and I believe these seemingly small changes are worth thinking about when you're spending a significant portion of your working life seated at a desk.</p>"},{"location":"about/office-setup/#monitor-mount-brateck-dual-wall-mount","title":"Monitor Mount: Brateck dual wall mount","text":"<p>The desk is flush with the wall (it's an IKEA kitchen benchtop) so I use a Brateck dual wall mounted monitor arm 17\"-32\". Installed on one of the arms is a VESA laptop tray holder which holds the MPB.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2024/01/03/hello-world/","title":"Hello World","text":"<p>1st blog post!</p>","tags":["networking","coding"]},{"location":"blog/2024/01/03/hello-world/#python-codeblock","title":"Python codeblock","text":"<p>Some <code>py</code> code</p> python code.py<pre><code>#print hello world!\ndef helloworld(x, y):\n    print(x, y,)\n\nhelloworld(\"Hello\", \"World\")\n</code></pre>","tags":["networking","coding"]},{"location":"iac/terraform/","title":"More than Certified in Terraform - Derek Morgan","text":"<p>Course projects: https://github.com/liftconfig/terraform-mtc-projects</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#section-1-introduction","title":"Section 1: Introduction","text":"","tags":["IaC","Terraform"]},{"location":"iac/terraform/#12-terraform-terminology","title":"12. Terraform Terminology","text":"<ul> <li>Declarative language:</li> <li>Walks through a dependency graph</li> <li>Requires state</li> <li>Idempotent</li> <li>Not always declarative. For example; provisioners (local/remote-exec) may operate procedurally</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#section-2-terraform-basics-and-docker","title":"Section 2: Terraform Basics and Docker","text":"","tags":["IaC","Terraform"]},{"location":"iac/terraform/#15-init-deep-dive","title":"15. Init Deep Dive","text":"<p>https://terraform.io/docs/cli/commands/init.html</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#16-terraform-dependency-lock","title":"16. Terraform Dependency Lock","text":"<p>https://terraform.io/docs/language/dependency-lock.html</p> <ul> <li>Locks the provider version</li> <li>Won't let you change the provider version with the lock in place unless you use <code>terraform init -upgrade</code>. This means you don't necessarily have to manually set the version in terraform:required_providers config.</li> <li>If you use <code>~&gt;</code> you can lock it so only minor version upgrades are permitted x.x.y <code>version = \"~&gt; 2.12.0\"</code> or x.y <code>version = \"~&gt; 2.12\"</code>. Whatever is the latest version of the furthest right number will be used.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#17-your-first-terraform-apply","title":"17. Your first terraform apply","text":"<ul> <li>Make sure AWS subnet has allocated public IPs enabled</li> <li>Spin up Cloud9 Instance with access option selected as SSH</li> <li>Allow SSH from local public IP into EC2 C9 instance inbound security group</li> <li>Use ssh-keygen to generate pub/private keys on local Linux container. Copy into <code>/home/vscode/.ssh/</code></li> <li>In C9 append pub key to <code>/home/ubuntu/.ssh/authorized_keys</code></li> <li><code>ssh ubuntu@x.x.x.x</code> from local Linux container</li> <li>You can then set the host in the docker provider to <code>host = \"ssh://ubuntu@x.x.x.x\"</code> and plan/apply terraform</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#18-terraform-plan-apply-deeper-dive","title":"18. Terraform plan &amp; apply deeper dive","text":"<ul> <li><code>terraform plan -out=plan1</code> creates an encoded plan file. The plan file is not encrypted so it needs to be stored somewhere safe</li> <li><code>terraform apply plan1</code> no confirmation dialogue, just creates resources</li> <li><code>terraform plan -destroy</code> simulate a destroy</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#19-referencing-other-resources","title":"19. Referencing other resources","text":"<p>https://terraform.io/docs/configuration/expressions.html</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#20-view-docker-image-in-browser","title":"20. View docker image in browser","text":"<ul> <li>To find public IP of EC2 instance <code>curl http://169.254.169.254/latest/meta-data/public-ipv4</code></li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#21-terraform-state-deeper-dive","title":"21. Terraform State Deeper Dive","text":"<ul> <li>Lineage: generated when your state file is originally created. Verify that it's the correct state</li> <li>terraform.tfstate.backup = previous state file before latest apply</li> <li>View the state file without accessing the file directly: <code>terraform show -json | jq</code>. jq prettifys the JSON output.</li> <li><code>terraform state list</code> lists all resources in the state file (1 line per resource). Quick way to check what resources have been provisioned without too much detail.</li> <li><code>terraform state show xxxx</code> shows the attributes or a resource in the state file</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#22-terraform-console-outputs","title":"22. Terraform Console &amp; Outputs","text":"<ul> <li>Use outputs to display state information which can then be used by other apps or terraform modules</li> <li>Use <code>terraform console</code> to query the attributes without having to look through the state file</li> </ul> <pre><code>  vscode \u279c /workspaces/terraform-associate/  terraform-docker $ terraform console\n  &gt; docker_container.nodered_container.name\n  \"nodered\"\n  &gt; docker_container.nodered_container.id\n  \"ee6cc21182468fb448213865632303360d99db6aaf56be5  fa1bbd15038ae7001\"\n  &gt; docker_container.nodered_container. network_data[0].ip_address\n  \"172.17.0.2\"\n</code></pre> <ul> <li>Add an output resource</li> </ul> <pre><code>  output \"ip-address\" {\n  value = docker_container.nodered_container.network_data[0].ip_address\n  description = \"The IP Address of the container\"\n  }\n</code></pre> <ul> <li>After output resources have been created, you can use <code>terraform output</code> to show the value of all output resources</li> </ul> <pre><code>  vscode \u279c /workspaces/terraform-associate/terraform-docker $ terraform output\n  IP-Address = \"172.17.0.2\"\n  container-name = \"nodered\"\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#23-terraform-functions","title":"23. Terraform Functions","text":"<p>https://terraform.io/docs/configuration/functions/join.html</p> <ul> <li><code>join(separator, list)</code></li> <li><code>join (\"+\", [\"thing\", 1]) = \"thing+1\"</code></li> </ul> <pre><code>  &gt; docker_container.nodered_container.network_data[0].ip_address\n  \"172.17.0.3\"\n  &gt; docker_container.nodered_container.ports[0].external\n  1880\n  &gt; join(\":\", [docker_container.nodered_container.network_data[0].ip_address, docker_container.nodered_container.ports[0].external])\n  \"172.17.0.3:1880\"\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#24-the-random-resource","title":"24. The Random Resource","text":"<p>https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/string</p> <ul> <li>Can be used for unique resources names</li> </ul> <pre><code>  resource \"random_string\" \"random\" {\n    length = 4\n    special = false\n    upper = false\n  }\n\n  resource \"docker_container\" \"nodered_container\" {\n    name  = join(\"-\",[\"nodered\", random_string.random.result])\n    image = docker_image.nodered_image.image_id\n    ports {\n      internal = 1880\n      # external = 1880\n    }\n  }\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#25-multiple-resources-and-count","title":"25. Multiple Resources and Count","text":"<p>https://developer.hashicorp.com/terraform/language/meta-arguments/count</p> <ul> <li>Count.index will reference the current resource count #. Combine with random_string to reference a matching random_string index.</li> </ul> <pre><code>  resource \"random_string\" \"random\" {\n    count = 2\n    length = 4\n    special = false\n    upper = false\n  }\n\n  resource \"docker_container\" \"nodered_container\" {\n    count = 2\n    name  = join(\"-\",[\"nodered\", random_string.random[count.index].result])\n    image = docker_image.nodered_image.image_id\n    ports {\n      internal = 1880\n      # external = 1880\n    }\n  }\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#26-the-splat-expression","title":"26. The splat expression","text":"<p>https://developer.hashicorp.com/terraform/language/expressions/splat</p> <ul> <li>Used like a for loop, but allows you to more concisely reference all the resources created by count</li> </ul> <pre><code>  vscode \u279c /workspaces/terraform-associate/terraform-docker $ terraform console\n  &gt; docker_container.nodered_container[*].name\n  [\n    \"nodered-s061\",\n    \"nodered-9pu5\",\n  ]\n\n  output \"container-name\" {\n    value = docker_container.nodered_container[*].name\n    description = \"The name of the container\"\n  }\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#27-for-expression","title":"27. For Expression","text":"<pre><code>&gt; [for i in [1, 2, 3]: i + 1]\n[\n  2,\n  3,\n  4,\n]\n&gt; [for i in docker_container.nodered_container[*]: i.name]\n[\n  \"nodered-s061\",\n  \"nodered-9pu5\",\n]\n&gt; [for i in docker_container.nodered_container[*]: join(\":\",[i.network_data[0].ip_address, i.ports[0][\"external\"]])] \n[\n  \"172.17.0.3:32776\",\n  \"172.17.0.2:32775\",\n]\n\noutput \"container-name\" {\n  value = docker_container.nodered_container[*].name\n  description = \"The name of the container\"\n}\n\noutput \"ip-address\" {\n  value = [for i in docker_container.nodered_container[*]: join(\":\",[i.network_data[0].ip_address, i.ports[0][\"external\"]])] \n  description = \"The IP Address and external port of the container\"\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#28-tainting-resources","title":"28. Tainting Resources","text":"<ul> <li>Deprecated in favour of <code>-replace=...</code> option when using plan/apply</li> <li>Way to force a resource to be destroyed and re-created. Example use case is if you need to re-apply a configuration from a volume. Similar to rebooting / reloading a daemon</li> <li>Be very careful with taint. For example if you taint the random_string resource, the resource that relies on it for its name would also get replaced on next apply</li> </ul> <pre><code>vscode \u279c /workspaces/terraform-associate/terraform-docker $ terraform taint random_string.random[0]\nResource instance random_string.random[0] has been marked as tainted.\nvscode \u279c /workspaces/terraform-associate/terraform-docker $ terraform plan\n</code></pre> <ul> <li>Untaint a resource <code>terraform untaint random_string.random[0]</code></li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#29-state-locking-breaking-state","title":"29. State locking &amp; breaking state","text":"<ul> <li><code>terraform apply -lock=true</code> is the default. If you don't lock the state there's a potential for corruption if multiple updates are done simultaneously.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#30-terraform-import","title":"30. Terraform import","text":"<p>https://developer.hashicorp.com/terraform/cli/import</p> <p><code>terraform import docker_container.nodered_container2 $(docker inspect --format=\"{{.ID}}\" nodered-3pfl)</code></p> <ul> <li>You can find the above import statement in the import section of the terraform docker provider.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#31-terraform-refresh-and-state-rm","title":"31. Terraform Refresh and State rm","text":"<ul> <li><code>terraform refresh</code> manually refresh state. If an object name has changed this will update the state file without having to apply.</li> <li><code>terraform state rm random_string.random[1]</code> Manually remove a resource from the state file. Only should be done when you don't want to run a terraform apply immediately (if for example, you're deleting a random_string resources that is also used for the name of another resource).</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#32-adding-variables","title":"32. Adding Variables","text":"<p>https://developer.hashicorp.com/terraform/language/values/variables</p> <ul> <li>If you don't define a default value or a value, the console will ask you for a value on every plan/apply/destroy</li> <li>You can specify the value on the CLI <code>terraform plan -var ext_port=1880</code></li> <li>You can specify the value using ENV variables <code>export TF_VAR_ext_port=1880</code>. Unset with <code>unset TF_VAR_ext_port</code></li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#33-variable-validation","title":"33. Variable Validation","text":"<ul> <li>See variables link above. Allows you to put conditions and error messages within the variable block to validate the values</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#35-sensitive-variables","title":"35. Sensitive Variables","text":"<ul> <li><code>terraform.tfvars</code> is your variable definition file. This file should always be added to your git ignore file</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#36-variable-definition-procedure","title":"36. Variable Definition Procedure","text":"<ul> <li>Specify different tfvar file for different environments <code>terraform plan --var-file west.tfvars</code></li> <li>Any variables specified in the CLI will override the default terraform.tfvars file</li> <li>If you specify both a <code>--var-file</code> and a <code>-var</code> on the command line then order matters. The last item in the command will win e.g. <code>terraform plan -var-file=west.tfvars -var ext_port=2000</code> then the -var value of 2000 will be used. <code>terraform plan  -var ext_port=2000 -var-file=west.tfvars</code> then the value of ext_port from west.tfvars will be used.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#37-hiding-sensitive-values-from-cli","title":"37. Hiding sensitive values from CLI","text":"<ul> <li>Set <code>sensitive = true</code> in the variable</li> <li>If you try to use a sensitive variable in a non-sensitive output you will get the following error:</li> </ul> <pre><code>  Error: Output refers to sensitive values\n\n  on outputs.tf line 6:\n  6: output \"ip-address\"\n</code></pre> <ul> <li><code>terraform show | grep external</code> will also show as sensitive</li> <li>Only place sensitive variables are not hidden is in the terraform.tfstate file</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#38-the-bind-mount-and-local-exec","title":"38. The bind mount and local-exec","text":"<p>https://developer.hashicorp.com/terraform/language/resources/provisioners/local-exec</p> <ul> <li>Invokes a local executable on the machine running terraform after a resource has been created.</li> <li>Remote exec will do the same but on a remote machine</li> <li>Not recommended to use local-exec as it's not idempotent, will run on every apply. Use a configuration management tool like Ansible instead.</li> <li>Local-exec provisioner needs to run in a resource block. You can use null_resource for this</li> <li>Example - create a directory for a container's persistent volume using remote-exec:</li> </ul> <pre><code>  resource \"null_resource\" \"dockevol\" {\n    connection {\n      type = \"ssh\"\n      user = \"ubuntu\"\n      host = \"x.x.x.x\"\n      private_key = \"${file(\"../id_rsa\")}\"\n    }\n\n    provisioner \"remote-exec\" {\n      inline = [\n        \"mkdir /home/ubuntu/environment/noderedvol/ || true &amp;&amp; sudo chown -R 1000:1000 /home/ubuntu/environment/noderedvol/\"\n      ]\n    }\n\n  resource \"docker_container\" \"nodered_container\" {\n    count = var.container_count\n    name  = join(\"-\",[\"nodered\", random_string.random[count.index].result])\n    image = docker_image.nodered_image.image_id\n    ports {\n      internal = var.int_port\n      external = var.ext_port\n    }\n    volumes {\n      container_path = \"/data\"\n      host_path = \"/home/ubuntu/environment/noderedvol\"\n    }\n    depends_on = [ null_resource.dockervol ]\n  }\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#39-utilising-local-values","title":"39. Utilising Local Values","text":"<p>https://developer.hashicorp.com/terraform/language/values/locals</p> <ul> <li>Local values are like a traditional functions temporary local variables</li> <li>Example - creating a local var for counting the number of items in a list:</li> </ul> <pre><code>  ext_port = [1880, 1881, 1882, 1883]\n\n  locals {\n    container_count = length(var.ext_port)\n  }\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#40-min-max-functions-the-expand-expression","title":"40. Min &amp; Max functions. The expand expression","text":"<ul> <li>The expand expression can be used to expand a list of values so that they can be evaluated by the likes of min/max. These functions don't allow lists natively</li> <li><code>max([10, 20, 30]...), max is 30</code></li> </ul> <pre><code>  variable \"ext_port\" {\n    type = list\n\n    validation {\n      condition = max(var.ext_port...) &lt;= 65535 &amp;&amp; min(var.ext_port...) &gt; 0\n      error_message = \"The external port must be between 0 and 65535\"\n    }\n  }\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#41-path-references-and-string-interpolation","title":"41. Path references and string interpolation","text":"<p>https://developer.hashicorp.com/terraform/language/expressions/references</p> <ul> <li>Evaluates expression inside ${..}. Allows you to insert a variable in a string <code>\"Hello, ${var.name}!\"</code></li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#42-maps-and-lookups-the-image-variable","title":"42. Maps and Lookups: the Image Variable","text":"<p>https://stackoverflow.com/questions/11489428/how-to-make-vim-paste-from-and-copy-to-systems-clipboard https://developer.hashicorp.com/terraform/language/functions/lookup</p> <ul> <li>Use case is for setting the value of identifiers depending on the environment (prod, dev, test)</li> </ul> <pre><code>  variable \"env\" {\n    type = string\n    description = \"Env to deploy to\"\n    default = \"dev\"\n  }\n\n  variable \"image\" {\n    type = map\n    description = \"Image to container\"\n    default = {\n      dev = \"nodered/node-red:latest\"\n      prod = \"nodered/node-red:latest-minimal\"\n    }\n  }\n\n  resource \"docker_image\" \"nodered_image\" {\n    name = lookup(var.image, var.env)\n  }\n\n  $ terraform plan | grep name\n      + hostname                                    = (known after apply)\n      + name                                        = (known after apply)\n      + name        = \"nodered/node-red:latest\"\n  $ terraform plan -var=\"env=prod\" | grep name\n      + hostname                                    = (known after apply)\n      + name                                        = (known after apply)\n      + name        = \"nodered/node-red:latest-minimal\"\n</code></pre> <ul> <li>Example - setting ports for docker container based on environment:</li> </ul> <pre><code>  ext_port = {\n    dev = [1980, 1981]\n    prod = [1880, 1881]\n  } \n\n  variable \"ext_port\" {\n    type = map\n\n    validation {\n      condition = max(var.ext_port[\"dev\"]...) &lt;= 65535 &amp;&amp; min(var.ext_port[\"dev\"]...) &gt;= 1980\n      error_message = \"The external port must be between 0 and 65535\"\n    }\n\n    validation {\n      condition = max(var.ext_port[\"prod\"]...) &lt;= 1980 &amp;&amp; min(var.ext_port[\"prod\"]...) &gt;= 1880\n      error_message = \"The external port must be between 0 and 65535\"\n    }\n  }\n\n  locals {\n    container_count = length(lookup(var.ext_port, var.env))\n  }\n\n  resource \"docker_container\" \"nodered_container\" {\n    count = local.container_count\n    name  = join(\"-\",[\"nodered\", random_string.random[count.index].result])\n    image = docker_image.nodered_image.image_id\n    ports {\n      internal = var.int_port\n      external = lookup(var.ext_port,var.env)[count.index]\n    }\n    volumes {\n      container_path = \"/data\"\n      host_path = \"/home/ubuntu/environment/noderedvol\"\n    }\n    depends_on = [ null_resource.dockervol ]\n  }\n</code></pre> <p>Note you can't reference another variable in a variable definition so you can't use var.env in the ext_port validation</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#44-terraform-workspaces","title":"44. Terraform Workspaces","text":"<p>https://developer.hashicorp.com/terraform/cloud-docs/workspaces</p> <ul> <li>Isolated versions of the terraform state that allows you to deploy multiple versions of the same environment with different variables, counts etc.</li> <li>Typically, workspaces are tied to branches in git. Work better in small well-defined environments. Could become hard to manage if there are many differences between environments</li> <li>Only particular backends support multiple workspaces (most popular ones do)</li> <li>New folders for workspace state will be stored in <code>terraform.tfstat.d/\"workspace name\"</code></li> </ul> <pre><code>terraform workspace new dev\nterraform workspace new prod\nterraform workspace show\nterraform workspace list\n  default\n  dev\n* prod\n\nterraform workspace select dev\nterraform apply --auto-approve -var=\"env=dev\"\nApply complete! Resources: 6 added, 0 changed, 0 destroyed.\n\nOutputs:\n\ncontainer-name = [\n  \"nodered-q0tu\",\n  \"nodered-gwtn\",\n]\nip-address = [\n  \"172.17.0.3:1980\",\n  \"172.17.0.2:1981\",\n]\n\nterraform workspace select prod\nterraform apply --auto-approve -var=\"env=prod\"\n\nOutputs:\n\ncontainer-name = [\n  \"nodered-swel\",\n  \"nodered-25uo\",\n]\nip-address = [\n  \"172.17.0.5:1880\",\n  \"172.17.0.4:1881\",\n]\n\n~/environment $ docker image ls\nREPOSITORY         TAG              IMAGE ID       CREATED      SIZE\nnodered/node-red   latest-minimal   7b324af6f086   7 days ago   272MB\nnodered/node-red   latest           4eb056ef6be0   7 days ago   558MB\n~/environment $ docker ps\nCONTAINER ID   IMAGE          COMMAND             CREATED          STATUS                             PORTS                    NAMES\n909aad51f8ca   7b324af6f086   \"./entrypoint.sh\"   14 seconds ago   Up 11 seconds (health: starting)   0.0.0.0:1880-&gt;1880/tcp   nodered-swel\nf9da0351780d   7b324af6f086   \"./entrypoint.sh\"   14 seconds ago   Up 11 seconds (health: starting)   0.0.0.0:1881-&gt;1880/tcp   nodered-25uo\nbc7f1018bff3   4eb056ef6be0   \"./entrypoint.sh\"   2 minutes ago    Up 2 minutes (healthy)             0.0.0.0:1981-&gt;1880/tcp   nodered-gwtn\nc6412f9c4ce4   4eb056ef6be0   \"./entrypoint.sh\"   2 minutes ago    Up 2 minutes (healthy)             0.0.0.0:1980-&gt;1880/tcp   nodered-q0tu\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#45-referencing-your-workspaces","title":"45. Referencing your Workspaces","text":"<ul> <li>Use <code>terraform.workspace</code> instead of creating a var.env</li> <li>This means you don't have to specify the environment variable when doing a terraform apply (less chance of an error)</li> </ul> <pre><code>vscode \u279c /workspaces/terraform-associate/terraform-docker $ terraform workspace select prod\nvscode \u279c /workspaces/terraform-associate/terraform-docker $ terraform console\n&gt; terraform.workspace\n\"prod\"\n\nresource \"docker_image\" \"nodered_image\" {\n  name = lookup(var.image, terraform.workspace)\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#46-using-map-keys-instead-of-lookups","title":"46. Using Map Keys instead of Lookups","text":"<ul> <li>Map keys = new way of accessing map values without a lookup. Preferred way of using map in most scenarios</li> <li>Only reason to use a lookup over a map key is the default value you can specify <code>lookup(map, key, default)</code></li> </ul> <pre><code>ports {\n  internal = var.int_port\n  external = lookup(var.ext_port,terraform.workspace)[count.index]\n}\n\nports {\n  internal = var.int_port\n  external = var.ext_port[terraform.workspace][count.index]\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#section-3-modular-deployments","title":"Section 3: Modular Deployments","text":"","tags":["IaC","Terraform"]},{"location":"iac/terraform/#47-modules-intro","title":"47. Modules Intro","text":"","tags":["IaC","Terraform"]},{"location":"iac/terraform/#48-first-module","title":"48. First Module!","text":"<ul> <li>Move Terraform required providers and provider attributes into their own <code>providers.tf</code> file</li> <li>Run <code>terraform init</code> whenever a new module is used to create a resource</li> <li>Create a new module folder and base files <code>mkdir image/ &amp;&amp; cd image/ &amp;&amp; touch variables.tf main.tf outputs.tf providers.tf</code></li> <li>Passing outputs from a module:</li> </ul> <pre><code># --- root/main.tf ---\n\nmodule \"image\" {\n  source = \"./image\"\n}\n\nresource \"docker_container\" \"nodered_container\" {\n  count = local.container_count\n  name  = join(\"-\",[\"nodered\", terraform.workspace, random_string.random[count.index].result])\n  image = module.image.image_out\n\n# --- image/main.tf ---\n\nresource \"docker_image\" \"nodered_image\" {\n  name = nodred/node-red:latest\n}\n\n# --- image/outputs.tf ---\n\noutput \"image_out\" {\n  value = docker_image.nodered_image.image_id\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#49-module-variables","title":"49. Module Variables","text":"<ul> <li>Modules shouldn't have any hardcoded values and should be rarely changed. Only specific people should have access to edit modules</li> <li>Passing variables into modules:</li> </ul> <pre><code># --- main.tf ---\n\nmodule \"image\" {\n  source = \"./image\"\n  image_in = var.image[terraform.workspace]\n}\n\n# --- variables.tf ---\n\nvariable \"image\" {\n  type = map\n  description = \"Image to container\"\n  default = {\n    dev = \"nodered/node-red:latest\"\n    prod = \"nodered/node-red:latest-minimal\"\n  }\n}\n\n# --- image/main.tf ---\n\nresource \"docker_image\" \"nodered_image\" {\n  name = var.image_in\n}\n\n# --- image/variables.tf ---\n\nvariable \"image_in\" {\n  description = \"name of image\"\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#50-terraform-graph","title":"50. Terraform Graph","text":"<ul> <li>Terraform Graph combined with graphViz allows you to visually see your deployment dependencies</li> <li><code>Terraform validate</code> validate your configuration code without doing a plan/apply</li> <li>Install graphviz: <code>sudo apt install graphviz</code></li> <li>Create a PDF: <code>terraform graph | dot -Tpdf &gt; graph-plan.pdf</code></li> <li>Create a PNG: <code>terraform graph | dot -Tpng &gt; graph-plan.png</code></li> <li>Create a PNG of plan to destroy: `terraform graph -type=plan-destroy| dot -Tpng &gt; graph-destroy.png</li> <li>Very useful for finding dependency issues</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#51-troubleshooting-dependencies","title":"51. Troubleshooting Dependencies","text":"<ul> <li>Can create two kinds of manual dependencies - implicit and explicit</li> <li>Implicit: You reference one of the resources attributes within your calling resource</li> <li>Explicit: Use <code>depends_on</code> within a resource</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#52-the-container-module-module-outputs","title":"52. The Container Module + module outputs","text":"<ul> <li>Reference the outputs of the module in the main outputs file</li> </ul> <pre><code># --- container/main.tf ---\n\nresource \"docker_container\" \"nodered_container\" {\n  name  = var.name_in \n  image = var.image_in\n  ports {\n    internal = var.int_port_in\n    external = var.ext_port_in\n  }\n  volumes {\n    container_path = var.container_path_in\n    host_path = var.host_path_in\n  }\n}\n\n# --- container/outputs.tf ---\n\noutput \"container-name\" {\n  value = docker_container.nodered_container.name\n  description = \"The name of the container\"\n}\n\noutput \"ip-address\" {\n  value = [for i in docker_container.nodered_container[*]: join(\":\",[i.network_data[0].ip_address, i.ports[0][\"external\"]])] \n  description = \"The IP Address and external port of the container\"\n}\n\n# alternative:\noutput \"ip-address\" {\n  value = flatten(module.container[*].ip-address)\n  description = \"The IP Address and external port of the container\"\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#54-module-information-flow","title":"54. Module information flow","text":"<ul> <li>Information doesn't flow directly between modules. Variables are passed between modules as outputs and inputs via the root module.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#55-docker-volume","title":"55. Docker Volume","text":"<ul> <li>Consider if you need a separate module for certain resources or if they should be included within another module</li> <li>In this example each container will always have a volume so it makes sense to include it in the container module</li> <li>You can use the <code>volumes</code> block in the docker_container resource to create a volume but the only problem is these won't get removed with <code>terraform destroy</code></li> <li>Correct way is to use a docker_volume resource</li> </ul> <pre><code>resource \"docker_container\" \"nodered_container\" {\n  name  = var.name_in \n  image = var.image_in\n  ports {\n    internal = var.int_port_in\n    external = var.ext_port_in\n  }\n  volumes {\n    container_path = var.container_path_in\n    volume_name = docker_volume.container_volume.name\n  }\n}\n\nresource \"docker_volume\" \"container_volume\" {\n  name = \"${var.name_in}-volume\"\n}\n</code></pre> <pre><code>root@ip-172-31-0-155:/home/ubuntu/environment# docker volume ls\nDRIVER    VOLUME NAME\nlocal     nodered-dev-jtar-volume\nlocal     nodered-dev-zkyc-volume\nroot@ip-172-31-0-155:/home/ubuntu/environment# ls /var/lib/docker/volumes/nodered-dev-jtar-volume/_data/\nflows.json  lib  node_modules  package.json  settings.js\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#56-lifecycle-customisation-and-targeting","title":"56. Lifecycle Customisation and Targeting","text":"<p>https://developer.hashicorp.com/terraform/language/meta-arguments/lifecycle</p> <ul> <li>Lifecycle block arguments <code>create_before_destroy</code>, <code>prevent_destroy</code>, <code>ignore_changes</code></li> <li>Target a particular resource for destruction</li> </ul> <pre><code>$ terraform state list\nmodule.container[0].docker_container.nodered_container\nmodule.container[0].docker_volume.container_volume\nmodule.container[1].docker_container.nodered_container\nmodule.container[1].docker_volume.container_volume\nmodule.image.docker_image.nodered_image\n$ terraform destroy -target=module.container[0].docker_container.nodered_container\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#58-using-for_each","title":"58. Using for_each","text":"<p>https://developer.hashicorp.com/terraform/language/meta-arguments/for_each</p> <ul> <li>One type of design pattern, may not work for everyone</li> <li>Cycles through a map of objects</li> <li>Resources that use count use a numerical index, whereas for_each has a key value. A lot easier to troubleshoot and manage keys.</li> </ul> <pre><code>module.container[0].docker_container.nodered_container\nmodule.container[0].docker_volume.container_volume\n\nvs\n\nmodule.image[\"influxdb\"].docker_image.container_image\nmodule.image[\"nodered\"].docker_image.container_image\n</code></pre> <pre><code># --- root/main.tf ---\n\nlocals {\n  deployment = {\n    nodered = {\n      container_count = length(var.ext_port[\"nodered\"][terraform.workspace])\n      image = var.image[\"nodered\"][terraform.workspace]\n      int = 1880\n      ext = var.ext_port[\"nodered\"][terraform.workspace]\n      container_path = \"/data\"\n    }\n    influxdb = {\n      container_count = length(var.ext_port[\"influxdb\"][terraform.workspace])\n      image = var.image[\"influxdb\"][terraform.workspace]\n      int = 8086 \n      ext = var.ext_port[\"influxdb\"][terraform.workspace]\n      container_path = \"/var/lib/influxdb\"\n    }\n  }\n}\n\nmodule \"image\" {\n  source = \"./image\"\n  for_each = local.deployment\n  image_in = each.value.image\n}\n\nmodule \"container\" {\n  source = \"./container\"\n  for_each = local.deployment\n  count_in = each.value.container_count\n  name_in  = each.key\n  image_in = module.image[each.key].image_out\n  int_port_in = each.value.int\n  ext_port_in = each.value.ext\n  container_path_in = each.value.container_path\n}\n\n# --- root/terraform.tfvars ---\n\next_port = {\n  nodered = {\n    dev = [1980]\n    prod = [1880]\n  }\n  influxdb = {\n    dev = [8186, 8187]\n    prod = [8086]\n  }\n} \n\n# --- container/main.tf ---\n\nresource \"random_string\" \"random\" {\n  count = var.count_in\n  length = 4\n  special = false\n  upper = false\n}\n\nresource \"docker_container\" \"app_container\" {\n  count = var.count_in\n  name  =  join(\"-\",[var.name_in, terraform.workspace, random_string.random[count.index].result])\n  image = var.image_in\n  ports {\n    internal = var.int_port_in\n    external = var.ext_port_in[count.index]\n  }\n  volumes {\n    container_path = var.container_path_in\n    volume_name = docker_volume.container_volume[count.index].name\n  }\n}\n\nresource \"docker_volume\" \"container_volume\" {\n  count = var.count_in\n  name = \"${var.name_in}-${random_string.random[count.index].result}-volume\"\n  lifecycle {\n    prevent_destroy = false\n  }\n}\n\n$ terraform console\n&gt; local.deployment\n{\n  \"influxdb\" = {\n    \"image\" = \"influxdb:latest\"\n  }\n  \"nodered\" = {\n    \"image\" = \"nodered/node-red:latest\"\n  }\n}\n&gt; keys(local.deployment)\n[\n  \"influxdb\",\n  \"nodered\",\n]\n&gt; values(local.deployment)\n[\n  {\n    \"image\" = \"influxdb:latest\"\n  },\n  {\n    \"image\" = \"nodered/node-red:latest\"\n  },\n]\n&gt; values(local.deployment[\"nodered\"])\n[\n  \"nodered/node-red:latest\",\n]\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#61-new-outputs-and-map-transformations","title":"61. New Outputs and Map Transformations","text":"<ul> <li>Quickly build a map using a for loop</li> </ul> <pre><code>$ terraform console\n&gt; {for x in [1, 2, 3, \"blue\"]: x =&gt; \"fish\"}\n{\n  \"1\" = \"fish\"\n  \"2\" = \"fish\"\n  \"3\" = \"fish\"\n  \"blue\" = \"fish\"\n}\n</code></pre> <ul> <li>Used to build structured maps for module output</li> </ul> <pre><code># --- container/outputs.tf ---\n\noutput \"application_access\" {\n  value = {for x in docker_container.app_container[*]: x.name =&gt; join(\":\", [x.network_data[0].ip_address], x.ports[*][\"external\"])}\n}\n\n##For loop technically not necessary as the outputs aren't being manipulated. Can just use module.container for simplicity\noutput \"application_access\" {\n  value = [for x in module.container[*]: x]\n  description = \"The name and socket for each application.\"\n}\n\nApply complete! Resources: 4 added, 0 changed, 0 destroyed.\n\nOutputs:\n\napplication_access = [\n  {\n    \"influxdb\" = {\n      \"application_access\" = {\n        \"influxdb-dev-7tuy\" = \"172.17.0.3:8186\"\n        \"influxdb-dev-s70o\" = \"172.17.0.4:8187\"\n      }\n    }\n    \"nodered\" = {\n      \"application_access\" = {\n        \"nodered-dev-bz3i\" = \"172.17.0.2:1980\"\n      }\n    }\n  },\n]\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#62-grafana-apply-yourself","title":"62. Grafana apply yourself","text":"<p>https://grafana.com/docs/grafana/latest/installation/docker</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#64-self-referencing-and-provisioner-failure-modes","title":"64. Self Referencing and Provisioner Failure Modes","text":"<p>https://developer.hashicorp.com/terraform/language/resources/provisioners/syntax#the-self-object</p> <ul> <li>Allows the provisioner to reference the parent resource's attributes</li> <li>Example of backing up docker volume before deletion</li> </ul> <pre><code>resource \"docker_volume\" \"container_volume\" {\n  count = var.count_in\n  name = \"${var.name_in}-${random_string.random[count.index].result}-volume\"\n  lifecycle {\n    prevent_destroy = false\n  }\n  provisioner \"remote-exec\" {\n    when = destroy\n    on_failure = continue\n    connection {\n      host = \"x.x.x.x\"\n      type = \"ssh\"\n      user = \"ubuntu\"\n      private_key = \"${file(\"../../id_rsa\")}\"\n    }\n    inline = [\n      \"mkdir /home/ubuntu/environment/backup/\"\n    ]\n  }\n  provisioner \"remote-exec\" {\n    when = destroy\n    on_failure = fail\n    connection {\n      host = \"x.x.x.x\"\n      type = \"ssh\"\n      user = \"ubuntu\"\n      private_key = \"${file(\"../../id_rsa\")}\"\n    }\n    inline = [\n      \"sudo tar -czvf /home/ubuntu/environment/backup/${self.name}.tar.gz ${self.mountpoint}/\"\n    ]\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#65-terraform-apply-yourself-self-referencing","title":"65. Terraform apply yourself - self referencing","text":"<pre><code>resource \"docker_container\" \"app_container\" {\n  count = var.count_in\n  name  =  join(\"-\",[var.name_in, terraform.workspace, random_string.random[count.index].result])\n  image = var.image_in\n  ports {\n    internal = var.int_port_in\n    external = var.ext_port_in[count.index]\n  }\n  volumes {\n    container_path = var.container_path_in\n    volume_name = docker_volume.container_volume[count.index].name\n  }\n  provisioner remote-exec {\n    connection {\n      host = \"x.x.x.x\"\n      type = \"ssh\"\n      user = \"ubuntu\"\n      private_key = \"${file(\"../../id_rsa\")}\"\n    }\n    inline = [\n      \"echo ${self.name}: ${self.network_data[0].ip_address}:${join(\"\", [for x in self.ports[*][\"external\"]: x])} &gt;&gt; /home/ubuntu/environment/containers.txt\"\n    ]\n  }\n  provisioner \"remote-exec\" {\n    when = destroy\n    on_failure = continue\n    connection {\n      host = \"x.x.x.x\"\n      type = \"ssh\"\n      user = \"ubuntu\"\n      private_key = \"${file(\"../../id_rsa\")}\"\n    }\n    inline = [\n      \"rm -f /home/ubuntu/environment/containers.txt\"\n    ]\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#66-dynamic-blocks","title":"66. Dynamic Blocks","text":"<p>https://developer.hashicorp.com/terraform/language/expressions/dynamic-blocks</p> <ul> <li>Allows you to create repeatable nested blocks within a resource using for_each</li> <li>Overuse can make configuration hard to read and maintain</li> </ul> <pre><code># --- root/locals.tf ---\n\nlocals {\n  deployment = {\n    grafana = {\n      container_count = length(var.ext_port[\"grafana\"][terraform.workspace])\n      image           = var.image[\"grafana\"][terraform.workspace]\n      int             = 3000\n      ext             = var.ext_port[\"grafana\"][terraform.workspace]\n      volumes = [\n        { container_path_each = \"/var/lib/grafana\" },\n        { container_path_each = \"/etc/grafana\" }\n      ]\n    }\n  }\n}\n\n# --- root/main.tf ---\n\nmodule \"container\" {\n  source      = \"./container\"\n  for_each    = local.deployment\n  count_in    = each.value.container_count\n  name_in     = each.key\n  image_in    = module.image[each.key].image_out\n  int_port_in = each.value.int\n  ext_port_in = each.value.ext\n  volumes_in  = each.value.volumes\n}\n\n# --- container/main.tf ---\n\nresource \"docker_container\" \"app_container\" {\n  count = var.count_in\n  name  = join(\"-\", [var.name_in, terraform.workspace, random_string.random[count.index].result])\n  image = var.image_in\n  ports {\n    internal = var.int_port_in\n    external = var.ext_port_in[count.index]\n  }\n  dynamic \"volumes\" {\n    for_each = var.volumes_in\n    content {\n      container_path = volumes.value[\"container_path_each\"]\n      volume_name = docker_volume.container_volume[volumes.key].name\n    }\n  }\n}\n\nresource \"docker_volume\" \"container_volume\" {\n  count = length(var.volumes_in)\n  name  = \"${var.name_in}-${count.index}-volume\"\n  lifecycle {\n    prevent_destroy = false\n  }\n}\n</code></pre> <pre><code>$ docker inspect $(docker ps -a -q) | grep volume\n \"grafana-1-volume:/etc/grafana:rw\",\n \"grafana-0-volume:/var/lib/grafana:rw\"\n \"Type\": \"volume\",\n \"Name\": \"grafana-1-volume\",\n \"Source\": \"/var/lib/docker/volumes/grafana-1-volume/_data\",\n \"Type\": \"volume\",\n \"Name\": \"grafana-0-volume\",\n \"Source\": \"/var/lib/docker/volumes/grafana-0-volume/_data\",\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#67-nesting-the-volume-module","title":"67. Nesting the Volume module","text":"<ul> <li>When there are multiple containers (multiple external ports), a volume module will allow the correct number of modules to be created ()</li> </ul> <pre><code># --- root/locals.tf ---\n\nlocals {\n  deployment = {\n    nodered = {\n      container_count = length(var.ext_port[\"nodered\"][terraform.workspace])\n      image           = var.image[\"nodered\"][terraform.workspace]\n      int             = 1880\n      ext             = var.ext_port[\"nodered\"][terraform.workspace]\n      container_path  = \"/data\"\n      volumes = [\n        { container_path_each = \"/data\" }\n      ]\n    }\n    influxdb = {\n      container_count = length(var.ext_port[\"influxdb\"][terraform.workspace])\n      image           = var.image[\"influxdb\"][terraform.workspace]\n      int             = 8086\n      ext             = var.ext_port[\"influxdb\"][terraform.workspace]\n      container_path  = \"/var/lib/influxdb\"\n      volumes = [\n        { container_path_each = \"/var/lib/influxdb\" }\n      ]\n    }\n    grafana = {\n      container_count = length(var.ext_port[\"grafana\"][terraform.workspace])\n      image           = var.image[\"grafana\"][terraform.workspace]\n      int             = 3000\n      ext             = var.ext_port[\"grafana\"][terraform.workspace]\n      volumes = [\n        { container_path_each = \"/var/lib/grafana\" },\n        { container_path_each = \"/etc/grafana\" }\n      ]\n    }\n  }\n}\n\n# --- root/variables.tf ---\n\nvariable \"int_port\" {\n  type    = number\n  default = 1880\n\n  validation {\n    condition     = var.int_port == 1880\n    error_message = \"The internal port must be 1880\"\n  }\n}\n\n# --- root/terraform.tfvars ---\n\next_port = {\n  nodered = {\n    dev  = [1980]\n    prod = [1880]\n  }\n  influxdb = {\n    dev  = [8186]\n    prod = [8086]\n  }\n  grafana = {\n    dev  = [3100, 3101]\n    prod = [3000]\n  }\n} \n\n# --- root/main.tf ---\n\nmodule \"container\" {\n  source      = \"./container\"\n  for_each    = local.deployment\n  count_in    = each.value.container_count\n  name_in     = each.key\n  image_in    = module.image[each.key].image_out\n  int_port_in = each.value.int\n  ext_port_in = each.value.ext\n  volumes_in  = each.value.volumes\n}\n\n# --- root/outputs.tf ---\n\noutput \"application_access\" {\n  value       = [for x in module.container[*] : x]\n  description = \"The name and socket for each application.\"\n}\n\n# --- container/variables.tf ---\n\nvariable \"name_in\" {}\nvariable \"image_in\" {}\nvariable \"int_port_in\" {}\nvariable \"ext_port_in\" {}\nvariable \"count_in\" {}\nvariable \"volumes_in\" {}\n\n# --- container/main.tf ---\n\nresource \"docker_container\" \"app_container\" {\n  count = var.count_in\n  name  = join(\"-\", [var.name_in, terraform.workspace, random_string.random[count.index].result])\n  image = var.image_in\n  ports {\n    internal = var.int_port_in\n    external = var.ext_port_in[count.index]\n  }\n  dynamic \"volumes\" {\n    for_each = var.volumes_in\n    content {\n      container_path = volumes.value[\"container_path_each\"]\n      volume_name    = module.volume[count.index].volume_output[volumes.key]\n    }\n  }\n\nmodule \"volume\" {\n  source       = \"./volume\"\n  count        = var.count_in\n  volume_count = length(var.volumes_in)\n  volume_name  = \"${var.name_in}-${terraform.workspace}-${random_string.random[count.index].result}-volume\"\n}\n\n# --- container/outputs.tf ---\n\noutput \"application_access\" {\n  value = { for x in docker_container.app_container[*] : x.name =&gt; join(\":\", [x.network_data[0].ip_address], x.ports[*][\"external\"]) }\n}\n\n# --- container/volume/variables.tf ---\n\nvariable \"volume_count\" {}\nvariable \"volume_name\" {}\n\n# --- container/volume/main.tf ---\nresource \"docker_volume\" \"container_volume\" {\n  count = var.volume_count\n  name  = \"${var.volume_name}-${count.index}\"\n  lifecycle {\n    prevent_destroy = false\n  }\n  provisioner \"remote-exec\" {\n    when       = destroy\n    on_failure = continue\n    connection {\n      host        = \"x.x.x.x\"\n      type        = \"ssh\"\n      user        = \"ubuntu\"\n      private_key = file(\"../../id_rsa\")\n    }\n    inline = [\n      \"mkdir /home/ubuntu/environment/backup/\"\n    ]\n  }\n  provisioner \"remote-exec\" {\n    when       = destroy\n    on_failure = fail\n    connection {\n      host        = \"x.x.x.x\"\n      type        = \"ssh\"\n      user        = \"ubuntu\"\n      private_key = file(\"../../id_rsa\")\n    }\n    inline = [\n      \"sudo tar -czvf /home/ubuntu/environment/backup/${self.name}.tar.gz ${self.mountpoint}/\"\n    ]\n  }\n}\n\n#container/volume/outputs.tf\n\noutput \"volume_output\" {\n  value = docker_volume.container_volume[*].name\n}\n</code></pre> <pre><code>$ sudo tree /var/lib/docker/volumes\n/var/lib/docker/volumes\n\u251c\u2500\u2500 1d3f5154b76b183837c385fe30b34060eb6aff9e75560ac4c84631112c650904\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 _data\n\u251c\u2500\u2500 backingFsBlockDev\n\u251c\u2500\u2500 be650d694e83103874d9e889bd697080216be219f4a15b0c6bbf93619391def3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 _data\n\u251c\u2500\u2500 grafana-dev-qt6e-volume-0\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 _data\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 alerting\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 1\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0     \u2514\u2500\u2500 __default__.tmpl\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 csv\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 grafana.db\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 plugins\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 png\n\u251c\u2500\u2500 grafana-dev-qt6e-volume-1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 _data\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 grafana.ini\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ldap.toml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 provisioning\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 access-control\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 alerting\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 dashboards\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 datasources\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 notifiers\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 plugins\n\u251c\u2500\u2500 grafana-dev-zo9d-volume-0\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 _data\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 alerting\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 1\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0     \u2514\u2500\u2500 __default__.tmpl\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 csv\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 grafana.db\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 plugins\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 png\n\u251c\u2500\u2500 grafana-dev-zo9d-volume-1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 _data\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 grafana.ini\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ldap.toml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 provisioning\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 access-control\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 alerting\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 dashboards\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 datasources\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 notifiers\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 plugins\n\u2514\u2500\u2500 metadata.db\n\n36 directories, 10 files\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#68-weatherboard-dashboard-project","title":"68. Weatherboard Dashboard Project","text":"<ul> <li>Build weather monitoring app to monitor weather for rocket launches in Houston and Kennedy Space Center</li> <li> <p>Use nodered to pull from the openweather map api, insert the data into influxdb, and then use grafana to graph the data</p> </li> <li> <p>Signup and get API key from openweathermap.org</p> </li> <li>Setup default bucket in influxdb called \"weather\". Copy API key.</li> <li>Use nodered template found in resources. Add API key for http request to openweathermap.org, add influxdb API key and bucket name</li> <li>Add influxdb as a data source in grafana and import the dashboard found in resources</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#section-4-deploy-aws-resources-with-terraform","title":"Section 4: Deploy AWS Resources with Terraform","text":"","tags":["IaC","Terraform"]},{"location":"iac/terraform/#69-what-were-going-to-build","title":"69. What we're going to build","text":"<ul> <li>Standard 3 tier app with a K3 control plane and worker node using free tier (T2 micro for K3s)</li> <li>K3s doesn't use etcd but instead can use MySQL or PostgreSQL (Amazon RDS)</li> <li>Use provisioners to copy kubeconfig settings files from control plane to the Cloud9 control node. This will allow k8s commands to be run from the node to the cluster automatically using terraform.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#70a-configuring-terraform-cloud","title":"70a. Configuring Terraform Cloud","text":"<ul> <li>CLI driven workflow = Terraform workflow commands are run remotely via CLI (see execution modes below)</li> <li>API driven workflow = Use TFC APIs to initiate workflow</li> <li>Git driven workflow = changes in git trigger workflow</li> <li>Execution modes for a workspace:</li> <li>Remote (default) = Plan and apply occur on TFC infrastructure and reviews are done in the GUI</li> <li>Local = Plan and apply occur locally and TFC is only used for state synchronisation</li> <li>After specifying terraform cloud org and workspace in backends.tf use <code>terraform login</code> to request an API token to allow local TF to use TFC as state backend</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#70b-using-dev-container-ubuntu-to-deploy-to-aws-with-tfc-backend","title":"70b. Using Dev Container (Ubuntu) to deploy to AWS with TFC backend","text":"<ul> <li>Assuming roles using terraform (Reddit)</li> <li>Authenticating to AWS Provider with Terraform (Reddit)</li> <li> <p>aws-vault env vars</p> </li> <li> <p>Install Password Store and aws-vault in dockerfile</p> </li> </ul> <pre><code>RUN curl -L -o /usr/local/bin/aws-vault https://github.com/99designs/aws-vault/releases/latest/download/aws-vault-linux-$(dpkg --print-architecture)\nRUN chmod 755 /usr/local/bin/aws-vault\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    pass \n</code></pre> <ol> <li>Create GPG key to use with aws-vault, init pass, set env vars, add AWS account, login to TFC</li> </ol> <pre><code>gpg --full-generate-key #Follow prompts\ngpg --list-secret-keys --keyid-format LONG #Only needed if key-id isn't recorded when output\npass init &lt;gpg key-id&gt;\nexport AWS_VAULT_PASS_PREFIX=aws-vault\nexport AWS_VAULT_BACKEND=pass\nexport AWS_DEFAULT_REGION=ap-southeast-2\nexport AWS_MFA_SERIAL=arn:aws:iam::x:mfa/xxxxxxxxx\nexport GPG_TTY=$(tty)\naws-vault add aws-profile #Enter AWS Key ID &amp; Secret Access Key\naws-vault exec aws-profile #Enter AWS OTP\nterraform login #Enter TFC token\n</code></pre> <p>Example of AWS key and STS token in password-store:</p> <pre><code>$ tree ~/.password-store/\n/home/vscode/.password-store/\n\u2514\u2500\u2500 aws-vault\n    \u251c\u2500\u2500 aws-profile.gpg\n    \u2514\u2500\u2500 sts.GetSessionToken.gpg\n\n$ pass\nPassword Store\n\u2514\u2500\u2500 aws-vault\n    \u251c\u2500\u2500 aws-profile\n    \u2514\u2500\u2500 sts.GetSessionToken\n</code></pre> <p>After MFA Prompt, aws-vault opens a subshell with temp STS credentials added as env vars. Terraform will pick up the access key, secret access key, and session token from here. It will assume the specified role in the provider config and then execute the commands.</p> <pre><code>provider \"aws\" {\n  region = var.aws_region\n\n  assume_role {\n    duration = \"1h\"\n    role_arn = \"arn:aws:iam:::role/mtc-terraform\"\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#71-the-aws-provider","title":"71. The AWS Provider","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#72-deploy-a-vpc","title":"72. Deploy a VPC","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#73-remote-state-in-terraform-cloud","title":"73. Remote State in Terraform Cloud","text":"<ul> <li>TFC workspace settings:</li> <li>Add SSH keys for downloading TF modules from Git</li> <li>Manually lock state</li> <li>Deny destroy plans</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#76-the-cidrsubnet-function","title":"76. The cidrsubnet() Function","text":"<p>https://developer.hashicorp.com/terraform/language/functions/cidrsubnet</p> <ul> <li><code>range (a,b,c)</code> a = min, b = max, c = step</li> </ul> <pre><code>terraform console\n&gt; cidrsubnet(\"10.123.0.0/16\", 8, 20)\n\"10.123.20.0/24\"\n&gt; range (1, 6, 2)\ntolist([\n  1,\n  3,\n  5,\n])\n\n# --- root/main.tf ---\n\nmodule \"networking\" {\n  source = \"./networking\"\n  vpc_cidr = \"10.123.0.0/16\"\n  public_sn_count = 2\n  private_sn_count = 3\n  public_cidrs = [for i in range(2, 255, 2) : cidrsubnet(\"10.123.0.0/16\", 8, i)]\n  private_cidrs = [for i in range(1, 255, 2) : cidrsubnet(\"10.123.0.0/16\", 8, i)]\n}\n\n# --- networking/main.tf ---\n\nresource \"aws_subnet\" \"mtc_public_subnet\" {\n  count = var.public_sn_count\n  vpc_id = aws_vpc.mtc_vpc.id\n  cidr_block = var.public_cidrs[count.index]\n  map_public_ip_on_launch = true #defaults to false\n  availability_zone = [\"ap-southeast-2a\",\"ap-southeast-2b\",\"ap-southeast-2c\"][count.index]\n\n  tags = {\n    Name = \"mtc_public_${count.index + 1}\"\n  }\n}\n\n$ terraform state list | grep public\nmodule.networking.aws_subnet.mtc_public_subnet[0]\nmodule.networking.aws_subnet.mtc_public_subnet[1]\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#77-the-aws_availability_zones-data-source-78-the-random_shuffle-resource","title":"77. The aws_availability_zones Data Source + 78. The random_shuffle Resource","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/availability_zones</p> <pre><code># --- networking/main.tf ---\n\ndata \"aws_availability_zones\" \"available\" {}\n\nresource \"random_shuffle\" \"az_list\" {\n  input = data.aws_availability_zones.available.names\n  result_count = var.max_subnets\n}\n\nresource \"aws_subnet\" \"mtc_public_subnet\" {\n  ...\n  availability_zone = random_shuffle.az_list.result[count.index]\n  ...\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#80-route-tables-internet-gateway","title":"80. Route tables &amp; Internet Gateway","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/route_table https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/default_route_table https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway</p> <ul> <li>One internet gateway per VPC (no count etc. required)</li> <li>Caveat around the default route table - it's an existing resource that terraform \"adopts\". All routes will be removed/replaced</li> </ul> <pre><code>resource \"aws_default_route_table\" \"mtc_private_rt\" {\n  default_route_table_id = aws_vpc.mtc_vpc.default_route_table_id\n}\n\n#This sets the default route table in the VPC to the existing default route table that is created during VPC creation rather than assigning a new one\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#81-the-create_before_destroy-lifecycle-meta-argument","title":"81. The create_before_destroy Lifecycle Meta Argument","text":"<ul> <li>When making a change to a VPC that requires recreating the VPC (e.g. changing the CIDR block) terraform will not delete the internet gateway. Instead, it will try and associate it to the new VPC which doesn't exist.</li> </ul> <pre><code>  # module.networking.aws_internet_gateway.mtc_internet_gateway will be updated in-place\n  ~ resource \"aws_internet_gateway\" \"mtc_internet_gateway\" {\n        id       = \"igw-0196283b5867f33f8\"\n        tags     = {\n            \"Name\" = \"mtc_igw\"\n        }\n      ~ vpc_id   = \"vpc-0b39532bb43b7b98c\" -&gt; (known after apply)\n        # (3 unchanged attributes hidden)\n  }\n</code></pre> <ul> <li>Need to use create_before_destroy lifecycle argument on the VPC to tell Terraform to create a new VPC before destroying the old one</li> </ul> <pre><code>resource \"aws_vpc\" \"mtc_vpc\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"mtc_vpc_${random_integer.random.id}\"\n  }\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#82-security-groups","title":"82. Security Groups","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group</p> <ul> <li>Always a chance when modifying security groups of causing a very short interruption to traffic</li> <li>Can use nested <code>for_each</code> to access inner maps within locals and then use dynamic blocks to iterate through them.</li> </ul> <pre><code># --- root/locals.tf ---\n\nlocals {\n  security_groups = {\n    public = {\n      name        = \"public_sg\"\n      description = \"Security Group for Public Access\"\n      ingress = {\n        ssh = {\n          from        = 22\n          to          = 22\n          protocol    = \"tcp\"\n          cidr_blocks = [var.access_ip]\n        }\n        http = {\n          from        = 80\n          to          = 80\n          protocol    = \"tcp\"\n          cidr_blocks = [\"0.0.0.0/0\"]\n        }\n      }\n    }\n    rds = {\n      name        = \"rds_sg\"\n      description = \"RDS Access\"\n      ingress = {\n        mysql = {\n          from        = 3306\n          to          = 3306\n          protocol    = \"tcp\"\n          cidr_blocks = [local.vpc_cidr]\n        }\n      }\n    }\n  }\n}\n\n# --- root/main.tf ---\n\nmodule \"networking\" {\n  source           = \"./networking\"\n  vpc_cidr         = local.vpc_cidr\n  access_ip        = \"\"\n  security_groups  = local.security_groups\n  public_sn_count  = 2\n  private_sn_count = 4\n  max_subnets      = 20\n  public_cidrs     = [for i in range(2, 255, 2) : cidrsubnet(local.vpc_cidr, 8, i)]\n  private_cidrs    = [for i in range(1, 255, 2) : cidrsubnet(local.vpc_cidr, 8, i)]\n}\n\n# --- networking/main.tf ---\n\nresource \"aws_security_group\" \"mtc_sg\" {\n  for_each    = var.security_groups\n  name        = each.value.name\n  description = each.value.description\n  vpc_id      = aws_vpc.mtc_vpc.id\n\n  dynamic \"ingress\" {\n    for_each = each.value.ingress\n    content {\n      from_port   = ingress.value.from\n      to_port     = ingress.value.to\n      protocol    = ingress.value.protocol\n      cidr_blocks = ingress.value.cidr_blocks\n    }\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#85-vpc-rds-subnet-group-and-conditionals","title":"85. VPC RDS Subnet Group and Conditionals","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_subnet_group</p> <ul> <li>Need a db_subnet to create an RDS</li> <li>Conditionals allow you to control how many instances are deployed. Uses logical \"if variable == value, then x, else y\". Example:</li> </ul> <pre><code>&gt; \"us-east-1\" == \"us-east-1\" ? 3: 1\n3\n&gt; \"us-west-1\" == \"us-east-1\" ? 3: 1\n1\n&gt; true == true ? 1 : 0\n1\n&gt; false == true ? 1 : 0\n0\n&gt; true ? 1 : 0\n1\n&gt; false ? 1 : 0\n0\n</code></pre> <ul> <li>Conditional bool is useful to control whether a resource is deployed based on a flag. If <code>db_subnet_group = false</code> then subnet_group does not deploy</li> <li><code>count = var.db_subnet_group == true ? 1 : 0</code> can be shortened to <code>count = var.db_subnet_group ? 1 : 0</code></li> </ul> <pre><code># --- root/main.tf ---\n\nmodule \"networking\" {\n  source           = \"./networking\"\n  ...\n  db_subnet_group  = true\n}\n\nresource \"aws_db_subnet_group\" \"mtc_rds_subnetgroup\" {\n  count = var.db_subnet_group == true ? 1 : 0\n  name = \"mtc_rds_subnetgroup\"\n  subnet_ids = aws_subnet.mtc_private_subnet.*.id\n  tags = {\n    \"Name\" = \"mtc_rds_sng\"\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#86-basic-rds-setup","title":"86. Basic RDS Setup","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance</p> <ul> <li>Most K8s deployments you would use etcd but in this case using Rancher K3s it allows you to use a standard RDS (MySQL or Postgres) to store the data</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#89-the-terraform-providers-schema-command","title":"89. The terraform providers schema command","text":"<ul> <li>Shows the entire AWS schema. 65 Mbps file, 890000 lines</li> <li>example of where password is marked as sensitive in aws_db_instance</li> </ul> <pre><code>terraform providers schema -json | jq '.' &gt; schema.json\n\n        \"aws_db_instance\": {\n          \"version\": 2,\n          \"block\": {\n            \"attributes\": {\n              \"password\": {\n                \"type\": \"string\",\n                \"description_kind\": \"plain\",\n                \"optional\": true,\n                \"sensitive\": true\n              }\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#90-alb-setup","title":"90. ALB setup","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb</p> <ul> <li>Load balances K3s in public subnet. Usually these would be in private subnets, but there's no bastion host or NAT gateway in this scenario</li> <li>Subnets and security groups similar to <code>aws_db_instance</code></li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#92-alb-target-group-and-the-uuid-and-substr-functions","title":"92. ALB Target Group and the UUID and substr functions","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_target_group https://developer.hashicorp.com/terraform/language/functions/uuid https://developer.hashicorp.com/terraform/language/functions/substr</p> <ul> <li>use instead of the random function for naming</li> </ul> <pre><code>&gt; uuid()\nb5ee72a3-54dd-c4b8-551c-4bdc0204cedb\n\nsubstr(string, offset, length)\n\n&gt; substr (uuid(), 0, 4)\n\"b5ee\"\n\nresource \"aws_lb_target_group\" \"mtc_tg\" {\n  name = \"mtc-lb-tg-${substr(uuid(), 0, 3)}\"\n}\n</code></pre> <ul> <li> <p>Note, each time terraform apply is ran it will generate a new UUID. If this is used in a resource name it may try and destroy/re-create the resource each time (as is the case with ALB target group)</p> </li> <li> <p>create before destroy when changing lb_target_group port</p> </li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#93-alb-listener","title":"93. ALB listener","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_listener</p> <ul> <li>Receives the external traffic and forwards to target group</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#94-alb-lifecycle-policies-ignore_changes-and-create_before_destroy","title":"94. ALB lifecycle Policies: ignore_changes and create_before_destroy","text":"<p>https://developer.hashicorp.com/terraform/language/meta-arguments/lifecycle</p> <ul> <li>To prevent the alb target group from being replaced on each run using the UUID function for generating the name, use the ignore_changes lifecycle policy</li> <li>If replacing the target group (for example after the name is updated) the listener needs to reference the new target group before the old one is destroyed</li> <li>Solution: Use the create_before_destroy lifecycle policy on the target group</li> </ul> <pre><code>resource \"aws_lb_target_group\" \"mtc_tg\" {\n  name     = \"mtc-lb-tg-${substr(uuid(), 0, 3)}\"\n  port     = var.tg_port\n  protocol = var.tg_protocol\n  vpc_id   = var.vpc_id\n  lifecycle {\n    ignore_changes = [name]\n    create_before_destroy = true\n  }\n  health_check {\n    healthy_threshold   = var.lb_healthy_threshold\n    unhealthy_threshold = var.lb_unhealthy_threshold\n    timeout             = var.lb_timeout\n    interval            = var.lb_interval\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#96-the-aws_ami-datasource","title":"96. The aws_ami datasource","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ami</p> <ul> <li>Use awscli to search and sort Ubuntu images</li> </ul> <pre><code>aws ec2 describe-images --owners 099720109477 --filters \"Name=name,Values=ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\" --query 'Images[*].[ImageId, Name]' --output table | awk '{print $4,$2}' | sort\n\nLatest image: ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-20240207.1 ami-0d6f74b9139d26bf1\n</code></pre> <ul> <li>How to always get the latest version in terraform</li> </ul> <pre><code># --- compute/main.tf ---\n\ndata \"aws_ami\" \"server_ami\" {\n  most_recent = true\n  owners = [\"099720109477\"]\n\n  filter {\n    name = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\"]\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#97-ec2-instances","title":"97. EC2 instances","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#98-ssh-key-for-instance","title":"98. SSH Key for Instance","text":"<p>https://www.udemy.com/course/terraform-certified/learn/lecture/24789250#notes</p> <ul> <li>Pass public key as a file rather than a string</li> </ul> <pre><code># --- compute/main.tf ---\n\nresource \"aws_key_pair\" \"mtc_auth\" {\n  key_name = var.key_name\n  public_key = file(var.public_key_path)\n}\n\n# --- root/main.tf ---\n\nmodule \"compute\" {\n  source          = \"./compute\"\n  ...\n  public_key_path = \"../../id_rsa.pub\"\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#100-controlling-random_id-changes-with-keepers","title":"100. Controlling random_id Changes with Keepers","text":"<p>https://registry.terraform.io/providers/hashicorp/random/latest/docs#resource-keepers</p> <ul> <li>Use the random_id resource in some cases as the UUID method <code>name = \"mtc-lb-tg-${substr(uuid(), 0, 3)}\"</code> may not always generate what's required. UUID also changes on each apply which is usually not wanted.</li> <li>Keepers trigger a new random ID resource when the consumer of that resource is destroyed</li> <li>The resources all provide a map argument called keepers that can be populated with arbitrary key/value pairs that when one of the values is modified, a new random ID should be generated. Otherwise, random_id only generates randomness when it is first created.</li> <li>The key_name in the keepers block determines when a new random_id should be created (when the key_name is changed)</li> </ul> <pre><code>resource \"random_id\" \"mtc_node_id\" {\n  byte_length = 2\n  count       = var.instance_count\n  keepers = {\n    #Generate a new id each time a new key_name is changes. A instance is replaced by terraform whenever the key changes.\n    key_name = var.key_name\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#102-ec2-user-data-and-template-files","title":"102. EC2 User Data and Template Files","text":"<p>https://docs.k3s.io/installation https://developer.hashicorp.com/terraform/language/functions/templatefile</p> <ul> <li>Template files: Pass template file path and variables from terraform deployment <code>templatefile(path, vars)</code>, and it will generate the required output (can do JSON &amp; YAML)</li> <li>Similar to Ansible Jinja template</li> </ul> <pre><code># --- root/main.tf ---\n\nmodule \"compute\" {\n  source          = \"./compute\"\n  ...\n  user_data_path  = \"${path.root}/userdata.tpl\"\n  db_endpoint     = module.database.db_endpoint\n  dbname          = var.dbname\n  dbuser          = var.dbuser\n  dbpassword      = var.dbpassword\n}\n\n# --- compute/main.tf ---\n\nresource \"aws_instance\" \"mtc_node\" {\n  ...\n  user_data = templatefile(var.user_data_path,\n    {\n      nodename    = \"mtc-${random_id.mtc_node_id[count.index].dec}\"\n      db_endpoint = var.db_endpoint\n      dbname      = var.dbname\n      dbuser      = var.dbuser\n      dbpass      = var.dbpassword\n    }\n  )\n}\n\n# --- userdata.tpl ---\n\n#!/bin/bash\nsudo hostnamectl set-hostname ${nodename} &amp;&amp;\ncurl -sfL https://get.k3s.io | sh -s - server \\\n--datastore-endpoint=\"mysql://${dbuser}:${dbpass}@tcp(${db_endpoint})/${dbname}\" \\\n--write-kubeconfig-mode 644 \\\n--tls-san=$(curl http://169.254.169.254/latest/meta-data/public-ipv4) \\\n--token=\"th1s1sat0k3n!\"\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#104-deploying-nginx-on-kubernetes-cluster","title":"104. Deploying NGINX on Kubernetes Cluster!","text":"<pre><code># --- deployment.yaml ---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      # manage pods with the label app: nginx\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n          hostPort: 8000\n</code></pre> <pre><code>ubuntu@mtc-28454:~$ kubectl get nodes\nNAME        STATUS   ROLES                  AGE     VERSION\nmtc-28454   Ready    control-plane,master   3m40s   v1.28.6+k3s2\nubuntu@mtc-28454:~$ vim deployment.yaml\nubuntu@mtc-28454:~$ kubectl apply -f deployment.yaml \ndeployment.apps/nginx created\nubuntu@mtc-28454:~$ kubectl get pods\nNAME                     READY   STATUS              RESTARTS   AGE\nnginx-77d6466568-77dmw   0/1     Pending             0          8s\nnginx-77d6466568-j7bxx   0/1     ContainerCreating   0          8s\nubuntu@mtc-28454:~$ curl localhost:8000\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\n</code></pre> <ul> <li>Only 1x K3s node so 1/2 NGINX replicas is Pending</li> <li>Using RDS to share the state of the cluster, so as soon as the 2nd K3s instance is deployed it will join the cluster</li> </ul> <pre><code>ubuntu@mtc-28454:~$ kubectl get nodes\nNAME        STATUS   ROLES                  AGE   VERSION\nmtc-28454   Ready    control-plane,master   14m   v1.28.6+k3s2\nmtc-8953    Ready    control-plane,master   46s   v1.28.6+k3s2\nubuntu@mtc-28454:~$ kubectl get pods\nNAME                     READY   STATUS    RESTARTS   AGE\nnginx-77d6466568-j7bxx   1/1     Running   0          7m38s\nnginx-77d6466568-77dmw   1/1     Running   0          7m38s\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#105-add-k3-instances-to-alb-target-group","title":"105. Add K3 Instances to ALB target group","text":"<p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_target_group_attachment</p> <ul> <li>Configure target group attachment which assigns instances (targets) to an ALB target group</li> </ul> <pre><code># --- loadbalancing/outputs.tf ---\n\noutput \"lb_target_group_arn\" {\n  value = aws_lb_target_group.mtc_tg.arn\n}\n\n# --- root/main.tf ---\n\nmodule \"compute\" {\n  source              = \"./compute\"\n  instance_count      = 2\n  ...\n  lb_target_group_arn = module.loadbalancing.lb_target_group_arn\n}\n\n# --- compute/main.tf ---\n\nresource \"aws_lb_target_group_attachment\" \"mtc_tg_attach\" {\n  count            = var.instance_count\n  target_group_arn = var.lb_target_group_arn\n  target_id        = aws_instance.mtc_node[count.index].id\n  port             = 8000\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#106-adding-outputs-for-our-resources","title":"106. Adding Outputs for our Resources","text":"<ul> <li>Output to show ALB DNS name</li> </ul> <pre><code># --- loadbalancing/outputs.tf ---\n\noutput \"lb_endpoint\" {\n  value = aws_lb.mtc_lb.dns_name\n}\n\n# --- root/outputs.tf ---\n\noutput \"load_balancer_endpoint\" {\n  value = module.loadbalancing.lb_endpoint\n}\n</code></pre> <pre><code> $ terraform refresh\nmodule.networking.random_integer.random: Refreshing state... [id=41]\nmodule.compute.random_id.mtc_node_id[1]: Refreshing state... [id=Ivk]\n...\nOutputs:\n\nload_balancer_endpoint = \"mtc-loadbalancer-1200784660.ap-southeast-2.elb.amazonaws.com\"\n</code></pre> <ul> <li>Terraform refresh will refresh state and show the outputs without having to do an apply. Can also do a <code>terraform output</code> once the outputs have been created the first time.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#107-sensitive-outputs-and-how-to-access-them","title":"107. Sensitive Outputs and how to access them","text":"<ul> <li>Create output for EC2 instances name and IP</li> </ul> <pre><code># --- compute/outputs.tf ---\n\noutput \"instance\" {\n  value = aws_instance.mtc_node[*]\n}\n\n# --- root/outputs.tf ---\n\noutput \"instances\" {\n  value = {for i in module.compute.instance : i.tags.Name =&gt; i.public_ip}\n}\n</code></pre> <pre><code>terraform refresh\nOutputs:\n\ninstances = {\n  \"mtc_node-28454\" = \"3.106.116.78\"\n  \"mtc_node-8953\" = \"13.210.137.182\"\n}\nload_balancer_endpoint = \"mtc-loadbalancer-1200784660.ap-southeast-2.elb.amazonaws.com\"\n</code></pre> <ul> <li>In older versions of Terraform when you send all attributes of the instances in compute/outputs.tf output you would need to add <code>sensitive = true</code> to the outputs in the compute and root modules. Then you would need to output in JSON to get the values. With later versions you don't need this workaround because you aren't outputting the sensitive values in the root module.</li> </ul> <pre><code>terraform output -json | jq '.\"instances\".\"value\"'\n{\n  \"mtc_node-28454\": \"3.106.116.78\",\n  \"mtc_node-8953\": \"13.210.137.182\"\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#109-utilising-the-remote-and-local-exec-provisioner-to-scp-the-kubeconfig-file","title":"109. Utilising the remote and local-exec provisioner to SCP the Kubeconfig file","text":"<ul> <li>Install Kubectl to run K8s commands locally in devcontainer. Add to dockerfile</li> </ul> <pre><code>RUN curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\nRUN echo \"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /\" | tee /etc/apt/sources.list.d/kubernetes.list\n\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    kubectl\n</code></pre> <ul> <li>Remote provisioner will run delay.sh to check for the presence of k3s.yaml on the remote node, so it knows when the node is operational.</li> <li>Local provisioner copies k3s YAML config locally from k3s node and replaces local IP with the public IP. Then you can run kubectl commands locally and access the remote node.</li> <li>Local provisioner will remove the k3s config file upon destroy</li> </ul> <pre><code># --- compute/main.tf ---\n\nresource \"aws_instance\" \"mtc_node\" {\n    ...\n    provisioner \"remote-exec\" {\n    connection {\n      type        = \"ssh\"\n      host        = self.public_ip\n      user        = \"ubuntu\"\n      private_key = file(\"${path.cwd}/../../id_rsa\")\n    }\n    script = \"${path.cwd}/delay.sh\"\n    }\n    provisioner \"local-exec\" {\n    command = templatefile(\"${path.cwd}/scp_script.tpl\",\n      {\n        nodeip          = self.public_ip\n        k3s_path        = \"${path.cwd}/../../\"\n        nodename        = self.tags.Name\n        privatekey_path = \"${path.cwd}/../../id_rsa\"\n      }\n    )\n    }\n    provisioner \"local-exec\" {\n    when    = destroy\n    command = \"rm -f ${path.cwd}/../../k3s-${self.tags.Name}\"\n  }\n}\n</code></pre> <pre><code># --- delay.sh ---\n\n#!/bin/bash\nwhile [ ! -f /etc/rancher/k3s/k3s.yaml ]; do\n    echo -e \"Waiting for k3s to bootstrap...\"\n    sleep 3\ndone\n\n# --- scp_script.tpl ---\n\nscp -i ${privatekey_path} \\\n-o StrictHostKeyChecking=no \\\n-o UserKnownHostsFile=/dev/null \\\n-q ubuntu@${nodeip}:/etc/rancher/k3s/k3s.yaml ${k3s_path}/k3s-${nodename}.yaml &amp;&amp; \nsed -i 's/127.0.0.1/${nodeip}/' ${k3s_path}/k3s-${nodename}.yaml\n</code></pre> <pre><code># --- k3s-mtc_node-50332.yaml ---\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: ...\n    server: https://x.x.x.x:6443\n  name: default\ncontexts:\n- context:\n    cluster: default\n    user: default\n  name: default\ncurrent-context: default\nkind: Config\npreferences: {}\nusers:\n- name: default\n  user:\n    client-certificate-data: ...\n    client-key-data: ...\n</code></pre> <pre><code>$ export KUBECONFIG=/workspaces/terraform-associate/k3s-mtc_node-50332.yaml\n$ kubectl get nodes\nNAME        STATUS   ROLES                  AGE     VERSION\nmtc-50332   Ready    control-plane,master   4m41s   v1.28.6+k3s2\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#112-deploying-k8s-resources-from-our-cloud9-instance","title":"112. Deploying K8s Resources from our Cloud9 Instance","text":"<pre><code># --- nginx-dep.yaml ---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      # manage pods with the label app: nginx\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n          hostPort: 8000\n</code></pre> <pre><code>$ kubectl get nodes\nNAME        STATUS   ROLES                  AGE   VERSION\nmtc-50332   Ready    control-plane,master   51m   v1.28.6+k3s2\n$ kubectl create -f nginx-dep.yaml\ndeployment.apps/nginx created\n$ kubectl get pods\nNAME                     READY   STATUS              RESTARTS   AGE\nmtc-50332   Ready    control-plane,master   52m   v1.28.6+k3s2\n$ terraform output -json | jq '.\"load_balancer_endpoint\".\"value\"'\n\"mtc-loadbalancer-574255458.ap-southeast-2.elb.amazonaws.com\"\n$ curl mtc-loadbalancer-574255458.ap-southeast-2.elb.amazonaws.com\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#section-5-deploying-kubernetes-resources-with-terraform","title":"Section 5: Deploying Kubernetes Resources with Terraform","text":"","tags":["IaC","Terraform"]},{"location":"iac/terraform/#113-configuring-k8s-provider","title":"113. Configuring K8s provider","text":"<p>https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#114-our-first-k8s-deployment","title":"114. Our First K8s Deployment","text":"<ul> <li>For large K8s deployment, Terraform is not the right tool. Don't always play well together. Probably best to use native k8s tools or Helm/ArgoCD</li> <li>This deployment is node-red containers (behind ALB) with their own local volume storage (not shared EFS, EBS etc.)</li> </ul> <pre><code># --- root/main.tf ---\n\nresource \"kubernetes_deployment\" \"iotdep\" {\n  metadata {\n    name = \"iotdep\"\n    labels = {\n      app = \"iotapp\"\n    }\n  }\n\n  spec {\n    replicas = 1\n\n    selector {\n      match_labels = {\n        app = \"iotapp\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"iotapp\"\n        }\n      }\n\n      spec {\n        container {\n          image = \"nodered/node-red:latest\"\n          name  = \"nodered-container\"\n          volume_mount {\n            name       = \"nodered-vol\"\n            mount_path = \"/data\"\n          }\n          port {\n            container_port = 1880\n            host_port      = 8000\n          }\n        }\n        volume {\n          name = \"nodered-vol\"\n          empty_dir {\n            medium = \"\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#116-terraform-apply-yourself-3-k8s-deployments-using-for_each","title":"116. Terraform Apply Yourself - 3 k8s deployments using for_each","text":"<ul> <li>Deploy nodered, influxdb, and grafana using the one deployment resource</li> </ul> <pre><code># --- root/locals.tf ---\n\nlocals {\n  deployment = {\n    nodered = {\n      image      = \"nodered/node-red:latest\"\n      int        = 1880\n      ext        = 1880\n      volumepath = \"/data\"\n    }\n    influxdb = {\n      image      = \"influxdb\"\n      int        = 8086\n      ext        = 8086\n      volumepath = \"var/lib/influxdb\"\n    }\n    grafana = {\n      image      = \"grafana/grafana\"\n      int        = 3000\n      ext        = 3000\n      volumepath = \"var/lib/grafana\"\n    }\n  }\n}\n\n# --- root/mains.tf ---\n\nresource \"kubernetes_deployment\" \"iotdep\" {\n  for_each = local.deployment\n  metadata {\n    name = \"${each.key}-dep\"\n    labels = {\n      app = \"iotapp\"\n    }\n  }\n\n  spec {\n    replicas = 1\n\n    selector {\n      match_labels = {\n        app = \"iotapp\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"iotapp\"\n        }\n      }\n\n      spec {\n        container {\n          image = each.value.image\n          name  = \"${each.key}-container\"\n          volume_mount {\n            name       = \"${each.key}-vol\"\n            mount_path = each.value.volumepath\n          }\n          port {\n            container_port = each.value.int\n            host_port      = each.value.ext\n          }\n        }\n        volume {\n          name = \"${each.key}-vol\"\n          empty_dir {\n            medium = \"\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre> <pre><code>$ kubectl get deployments\nNAME           READY   UP-TO-DATE   AVAILABLE   AGE\nnodered-dep    0/1     1            0           3m16s\ngrafana-dep    1/1     1            1           3m16s\ninfluxdb-dep   1/1     1            1           3m16s\n\n$ kubectl get pods\nNAME                            READY   STATUS    RESTARTS   AGE\ngrafana-dep-66f59cdd49-xlz7n    1/1     Running   0          4m8s\ninfluxdb-dep-69bb978bfd-hjrxk   1/1     Running   0          4m8s\nnodered-dep-5867bf8c7c-5str7    1/1     Running   0          4m8s\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#117-terraform_remote_state-datasource-and-the-split-function","title":"117. Terraform_remote_state datasource and the split Function","text":"<p>https://developer.hashicorp.com/terraform/language/state/remote-state-data</p> <ul> <li>Pull values from a remote state file. Recommendation is to not use this if possible. You need full access to the workspace state. Better to use tfe_outputs data source.</li> <li>Use the output from the terraform-aws state file which shows the env var with the location of the K8s config file. Then use split to just get the file location.</li> </ul> <pre><code>$ terraform console\n&gt; split(\"=\", \"export KUBECONFIG=/workspaces/terraform-associate/terraform-aws/terraform-aws/../../k3s-mtc_node-59231.yaml\")[1]\n\"/workspaces/terraform-associate/terraform-aws/terraform-aws/../../k3s-mtc_node-59231.yaml\"\n&gt; split(\"=\", \"export KUBECONFIG=/workspaces/terraform-associate/terraform-aws/terraform-aws/../../k3s-mtc_node-59231.yaml\")\ntolist([\n  \"export KUBECONFIG\",\n  \"/workspaces/terraform-associate/terraform-aws/terraform-aws/../../k3s-mtc_node-59231.yaml\",\n])\n</code></pre> <ul> <li>Accessing tfstate from terraform-aws in TFC. <code>data.terraform_remote_state.kubeconfig.outputs.kubeconfig</code> has the location of the K8s config file.</li> </ul> <pre><code># --- root/datasources.tf ---\n\ndata \"terraform_remote_state\" \"kubeconfig\" {\n  backend = \"remote\"\n\n  config = {\n    organization = \"mtc-terraform-th\"\n    workspaces = {\n      name = \"mtc-dev\"\n    }\n  }\n}\n\n# --- root/providers.tf ---\n\nlocals {\n  config = data.terraform_remote_state.kubeconfig.outputs.kubeconfig\n}\nterraform {\n  required_providers {\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.26.0\"\n    }\n  }\n}\n\nprovider \"kubernetes\" {\n  config_path = split(\"=\",local.config[0])[1]\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#section-6-continuous-deployment-using-terraform-cloud","title":"Section 6: Continuous Deployment using Terraform Cloud","text":"","tags":["IaC","Terraform"]},{"location":"iac/terraform/#118-what-were-going-to-build","title":"118. What We're Going to Build","text":"<ul> <li>CI/CD pipeline</li> <li>GitHub Networking &amp; Compute Repos hosting modules</li> <li>GitHub hosting Deployment repo (main.tf)</li> <li>Oauth GitHub with Terraform Cloud so that when a change is made in the module repos it will be reflected in the modules in TFC. Also, so that a change in the deployment repo will deploy in TFC using a deployment workspace.</li> <li>Deployment envars in TFC will contain AWS credentials</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#120-setting-up-github","title":"120. Setting up GitHub","text":"<ul> <li>Pull repo https://github.com/derekops/terraform-aws-networking</li> <li>GitHub &gt; Settings &gt; Developer settings &gt; PAT</li> <li>When creating a module repo, the repo name must start with terraform-aws or TFC will not pick it up as a module</li> <li>Output below: clone repo, remove git, initialise a new repo, create new repo in GitHub GUI, then add the GitHub repo as origin source</li> </ul> <pre><code>git clone https://github.com/derekops/terraform-aws-networking.git\nrm -rf .git \ngit init &amp;&amp; git add .\ngit commit -m \"Git initial\"\ngit branch -M main\ngit remote add origin https://github.com/liftconfig/terraform-aws-networking.git\ngit status\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#121-configuring-terraform-cloud","title":"121. Configuring Terraform Cloud","text":"<p>Authorise TFC to access GitHub account. Create an Application in GitHub</p> <ol> <li>In terraform Cloud Org settings configure a VSC provider</li> <li>Link to GitHub to register a new OAuth Application https://github.com/settings/applications/new TFC provides all the steps to do this.</li> <li>Create a new workspace and chose Version Control Workflow. You will be able to select GitHub as a VCS provider.</li> <li>Choose a repository from GitHub</li> </ol>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#122-our-first-cloud-deployment","title":"122. Our First Cloud Deployment","text":"<ul> <li>TFC will pick up any variable file <code>*.auto.tfvars</code> and automatically use the variables in the configuration.</li> <li>When creating variables if you are using anything other than a string (list, map etc.) make sure to tick the HCL box or it will be inside quotes like a string.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#123-tfc-repo-based-modules","title":"123. TFC Repo-based modules","text":"<ul> <li>Publish private modules in TFC under registry &gt; modules</li> <li>Select VSC Provider and then a repo for the module (same as a VSC workflow workspace)</li> <li>\"Module source repository has no tags\" - A module requires Git tagging before it can be utilised.</li> </ul> <pre><code>$ git tag -a v1.0.0 -m \"first version\"\n$ git tag\nv1.0.0\n$ git push origin v1.0.0\nTo https://github.com/liftconfig/terraform-aws-networking.git\n * [new tag]         v1.0.0 -&gt; v1.0.0\n</code></pre> <ul> <li>Modules won't pick up the <code>*.auto.tfvars</code> file, so this needs to be specified outside the repository.</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#124-utilising-the-configuration-designer-to-create-a-deployment","title":"124. Utilising the Configuration Designer to Create a Deployment","text":"<ul> <li>Registry (where you can see your modules) &gt; Design configuration &gt; Select modules</li> <li>Add variables for each of the modules. You can use the outputs of other modules as inputs</li> </ul> <ul> <li>You can then copy the code output and publish to a new VSC repo</li> </ul> <pre><code># --- mtc-control/deployments/mtc-dev/main.tf ---\n\n//--------------------------------------------------------------------\n// Variables\n\n//--------------------------------------------------------------------\n// Modules\nmodule \"compute\" {\n  source  = \"app.terraform.io/mtc-terraform-th/compute/aws\"\n  version = \"1.0.1\"\n\n  aws_region = \"ap-southeast-2\"\n  public_key_material = \"ssh-rsa \"\n  public_sg = \"${module.networking.public_sg}\"\n  public_subnets = \"${module.networking.public_subnets}\"\n}\n\nmodule \"networking\" {\n  source  = \"app.terraform.io/mtc-terraform-th/networking/aws\"\n  version = \"1.0.0\"\n\n  access_ip = \"x.x.x.x\"\n  aws_region = \"ap-southeast-2\"\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#125-settings-up-providers-for-our-new-deployment","title":"125. Settings up Providers for our New Deployment","text":"<ul> <li>Here we're using terraform code (outside of Git/TFC) to deploy code to Git/TFC</li> <li>Deploy the above main.tf code to GitHub, then run using TFC</li> <li>Create a new GitHub repository and attach repository to TFC workspace all using Terraform code</li> <li>Modules are scoped to the organisation in TFC so the above module source will all work</li> </ul> <pre><code># --- root/providers.tf ---\n\nterraform {\n  required_providers {\n    github = {\n      source = \"integrations/github\"\n      version = \"4.13.0\"\n    }\n\n    tfe = {\n      source = \"hashicorp/tfe\"\n    }\n  }\n}\n\nprovider \"github\" {\n  token = var.github_token\n  owner = var.github_owner\n}\n\nprovider \"tfe\" {\n  token = var.tfe_token\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#127-configuring-our-github-resources-in-terraform","title":"127. Configuring our GitHub Resources in Terraform","text":"<ul> <li>In local TF - Create repository, default branch, and upload main.tf</li> </ul> <pre><code># --- root/main.tf ---\n\nresource \"github_repository\" \"mtc_repo\" {\n  name = \"mtc-dev-repo\"\n  description = \"VPC and Compute Resources\"\n  auto_init  = true\n  license_template = \"mit\"\n\n  visibility = \"private\"\n}\n\nresource \"github_branch_default\" \"default\" {\n  repository = github_repository.mtc_repo.name\n  branch = \"main\"\n}\n\nresource \"github_repository_file\" \"maintf\" {\n  repository = github_repository.mtc_repo.name\n  branch = \"main\"\n  file = \"main.tf\"\n  content = file (\"./deployments/mtc-dev/main.tf\")\n  #not uploading file, you are creating a new file and extracting content from main.tf\n  commit_message = \"Managed by Terraform\"\n  commit_author = \"tim\"\n  commit_email = \"tim@tim.com\"\n  overwrite_on_create = true\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#128-configuring-our-terraform-cloud-resources-in-terraform","title":"128. Configuring our Terraform Cloud Resources in Terraform","text":"<ul> <li>In local TF create TFC resources: mtc_oauth client to github, workspace using repo from GitHub, workspace environment variables for AWS</li> </ul> <pre><code># --- root/main.tf ---\nresource \"tfe_oauth_client\" \"mtc_oauth\" {\n  organization     = local.organization\n  api_url          = \"https://api.github.com\"\n  http_url         = \"https://github.com\"\n  oauth_token      = var.github_token\n  service_provider = \"github\"\n}\n\nresource \"tfe_workspace\" \"mtc_workspace\" {\n  name         = github_repository.mtc_repo.name\n  organization = local.organization\n  vcs_repo {\n    identifier     = \"${var.github_owner}/${github_repository.mtc_repo.name}\"\n    oauth_token_id = tfe_oauth_client.mtc_oauth.oauth_token_id\n  }\n}\n\nresource \"tfe_variable\" \"aws_creds\" {\n  for_each     = local.aws_creds\n  key          = each.key\n  value        = each.value\n  category     = \"env\"\n  sensitive    = true\n  workspace_id = tfe_workspace.mtc_workspace.id\n  description  = \"AWS creds\"\n}\n</code></pre> <ul> <li>After the workspace is created a plan will automatically run using the main.tf in the mtc_repo</li> </ul> <p>DO NOT run destroy from local TF (destroying TFC workspace, GitHub repo etc) without running a destroy from TFC workspace. Otherwise, you are left with all the AWS resources created from the workspace</p>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#130-pushing-and-pulling-remote-state","title":"130. Pushing and pulling remote state","text":"<ul> <li>Locally pull the state down from the mtc-dev-repo, modify and push back up. Should be an extremely rare scenario that would call for this.</li> </ul> <pre><code># --- mtc-control/deployments/mtc-dev/main.tf ---\n\nterraform {\n  backend \"remote\" {\n    organization = \"mtc-terraform-th\"\n\n    workspaces {\n      name = \"mtc-dev-repo\"\n    }\n  }\n}\n</code></pre> <pre><code>terraform init\nterraform state pull &gt;&gt; terraform.tfstate\nterraform state push terraform.tfstate\nFailed to write state: cannot overwrite existing state with serial 1 with a different state that has the same serial\n# need to increment the serial # in the state, then you can push back up to TFC.\nterraform state push terraform.tfstate\nAcquiring state lock. This may take a few moments...\nReleasing state lock. This may take a few moments...\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#131-updating-our-deployment-modules-and-destroying-it","title":"131. Updating our Deployment Modules and Destroying it","text":"<ul> <li>Updated variable in terraform-aws-compute module repo and then publish as new module version</li> </ul> <pre><code>git add .\ngit commit -m \"updated key name\"\n[main 20b9a08] updated key name\n 1 file changed, 1 insertion(+), 1 deletion(-)\ngit tag -a v1.0.2 -m \"updated keyname\"\ngit push origin v1.0.2\n\nEnumerating objects: 6, done.\nCounting objects: 100% (6/6), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (4/4), 438 bytes | 438.00 KiB/s, done.\nTotal 4 (delta 2), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/liftconfig/terraform-aws-compute.git\n * [new tag]         v1.0.2 -&gt; v1.0.2\n</code></pre> <ul> <li>Update module version in main.tf to use new version</li> </ul> <pre><code># --- mtc-control/deployments/mtc-dev/main.tf ---\n\n//--------------------------------------------------------------------\n// Variables\n\n//--------------------------------------------------------------------\n// Modules\nmodule \"compute\" {\n  source  = \"app.terraform.io/mtc-terraform-th/compute/aws\"\n  version = \"1.0.2\"\n\n  aws_region = \"ap-southeast-2\"\n  public_key_material = \"ssh-rsa \"\n  public_sg = \"${module.networking.public_sg}\"\n  public_subnets = \"${module.networking.public_subnets}\"\n}\n\nmodule \"networking\" {\n  source  = \"app.terraform.io/mtc-terraform-th/networking/aws\"\n  version = \"1.0.0\"\n\n  access_ip = \"x.x.x.x\"\n  aws_region = \"ap-southeast-2\"\n}\n</code></pre>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#cleaning-up","title":"Cleaning up","text":"<ul> <li>Run destroy in TFC mtc-dev-repo workspace</li> <li>Destroy mtc-dev-repo GitHub repo and TFC workspace</li> <li>Destroy resources from aws-networking TFC workspace (created prior to turning into module)</li> <li>Delete TFC token, GitHub PAT, AWS Access Key</li> </ul>","tags":["IaC","Terraform"]},{"location":"iac/terraform/#time-to-complete-course","title":"Time to complete course","text":"Date Day Time 15/01/24 MON 3H 16/01/24 TUE 1H 17/01/24 WED 2H 18/01/24 THU 1.5H 19/01/24 FRI 2H 20/01/24 SAT 1.5H 21/01/24 SUN 1H 22/01/24 MON 2H 23/01/24 TUE 1H 24/01/24 WED 1H 25/01/24 THU 2H 26/01/24 FRI 1H 28/01/24 SUN 2H 29/01/24 MON 3H 30/01/24 TUE 1.5H 31/01/24 WED 1H 03/02/24 SAT 1H 04/02/24 SUN 2.5H 05/02/24 MON 1H 06/02/24 TUE 1H 11/02/24 SUN 2H 12/02/24 MON 2H 13/02/24 TUE 2H 14/02/24 THU 1.5H 18/02/24 FRI 0.5H 19/02/24 MON 1H 20/02/24 TUE 0.5H 26/02/24 MON 1.5H 27/02/24 TUE 1.5H 28/02/24 WED 2H <ul> <li>Total = 46.5.</li> <li>Course video length = 12.5 = 4x to complete</li> <li>Average ~1 hour a day / 7.75 hours a week</li> </ul>","tags":["IaC","Terraform"]},{"location":"networking/fortinet/","title":"Coming Soon","text":""},{"location":"networking/iosxr/","title":"Coming Soon","text":""},{"location":"networking/nsxt/","title":"Coming Soon","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/networking/","title":"networking","text":""},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#iac","title":"IaC","text":"<ul> <li>Terraform</li> </ul>"},{"location":"tags/#terraform","title":"Terraform","text":"<ul> <li>Terraform</li> </ul>"},{"location":"tags/#coding","title":"coding","text":"<ul> <li>Hello World</li> </ul>"},{"location":"tags/#networking","title":"networking","text":"<ul> <li>Hello World</li> </ul>"}]}